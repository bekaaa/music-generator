{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import _pickle as pickle\n",
    "import glob\n",
    "from music21 import note, chord, instrument, converter\n",
    "from keras.layers import LSTM, Dense, Dropout, Activation, Input\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to call all subfunctions in the notebook.\n",
    "def train_network():\n",
    "    # get data and convert it to notes\n",
    "    notes = get_notes()\n",
    "    # number of vocabs\n",
    "    n_vocab = len(set(notes))\n",
    "    # prepare data\n",
    "    NetworkInput, NetworkOutut = prepare_data(notes, n_vocab)\n",
    "    # get model\n",
    "    model = get_model(NetworkInput.shape[1:], n_vocab)\n",
    "    # train\n",
    "    train(model, NetworkInput, NetworkOutut)\n",
    "#--------------------------------------------------------------------\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notes are loaded properly using the saved pickle\n"
     ]
    }
   ],
   "source": [
    "def get_notes(quick=False):\n",
    "    ''' Read input midi files and convert them to notes\n",
    "        Also quick refers to using the saved notes.pkl to retrieve notes instead of reading midi files.\n",
    "    '''\n",
    "    input_folder = './data/input_midi/'\n",
    "    output_folder = './data/'\n",
    "    notes = []\n",
    "    \n",
    "    if quick :\n",
    "        try :\n",
    "            with open(output_folder+'notes.pkl','rb') as f :\n",
    "                notes = pickle.load(f)\n",
    "            print('Notes are loaded properly using the saved pickle')\n",
    "            return notes, len(set(notes))\n",
    "        except :\n",
    "            print('It\\'s not possible to do it quick,\\n reading midi files....')\n",
    "            return get_notes()\n",
    "    \n",
    "    for file in glob.glob(input_folder+'*.mid'):\n",
    "        midi = converter.parse(file)\n",
    "        notes_to_parse  = []\n",
    "        parts = instrument.partitionByInstrument(midi)\n",
    "        \n",
    "        if parts :\n",
    "            notes_to_parse = parts.parts[0].recurse()\n",
    "        else :\n",
    "            notes_to_parse = parts.flat_notes\n",
    "        \n",
    "        for element in notes_to_parse:\n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.pitch))\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                notes.append('.'.join(str(e) for e in c.pitches))\n",
    "            else : # it shouldn't reach here.\n",
    "                pass\n",
    "        with open(output_folder+'notes.pkl', 'wb') as f :\n",
    "            pickle.dump(notes, f)\n",
    "        print('data loaded properly and saved to disk as notes.pkl.')\n",
    "        return notes, len(set(notes))\n",
    "#--------------------------------------------------------\n",
    "notes, n_vocab = get_notes(quick=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape =  (620, 100, 1) \n",
      "Output shape =  (620, 720, 1)\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(notes, n_vocab):\n",
    "    ''' create input sequences and output notes '''\n",
    "    sequence_length = 100\n",
    "    NetworkInput = []\n",
    "    NetworkOutput = []\n",
    "    # create a mapping to the notes\n",
    "    note_to_int = dict((note,i) for i,note in enumerate(notes))\n",
    "    \n",
    "    for i in range(len(notes)-sequence_length):\n",
    "        in_seq = notes[i : i+sequence_length]\n",
    "        out_note = notes[i+sequence_length]\n",
    "        NetworkInput.append( [ note_to_int[note] for note in in_seq ] )\n",
    "        NetworkOutput.append(note_to_int[out_note])\n",
    "    \n",
    "    n_patterns = len(NetworkOutput)\n",
    "    \n",
    "    NetworkInput = np.reshape(NetworkInput, (n_patterns, sequence_length, 1))\n",
    "    NetworkOutput = np_utils.to_categorical(NetworkOutput)\n",
    "    NetworkInput = NetworkInput / float(n_vocab)\n",
    "    NetworkOutput = NetworkOutput.reshape(-1,NetworkOutput.shape[1],1)\n",
    "    print('Input shape = ',NetworkInput.shape, '\\nOutput shape = ', NetworkOutput.shape)\n",
    "    return NetworkInput, NetworkOutput\n",
    "#---------------------------------------\n",
    "NetworkInput, NetworkOutput = prepare_data(notes, n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 100, 512)          1052672   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 100, 512)          0         \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 100, 512)          2099200   \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 100, 512)          0         \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 100, 512)          2099200   \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 100, 512)          0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100, 256)          131328    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 100, 256)          0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100, 32)           8224      \n",
      "=================================================================\n",
      "Total params: 5,390,624\n",
      "Trainable params: 5,390,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model(input_shape, n_vocab):\n",
    "    X_input = Input(input_shape)\n",
    "    X = LSTM(512, activation='relu', return_sequences=True)(X_input)\n",
    "    X = Dropout(.3)(X)\n",
    "    X = LSTM(512, activation='relu', return_sequences=True)(X)\n",
    "    X = Dropout(.3)(X)\n",
    "    X = LSTM(512, activation='relu', return_sequences=True)(X)\n",
    "    X = Dropout(.3)(X)\n",
    "    X = Dense(256, activation='relu')(X)\n",
    "    X = Dropout(.3)(X)\n",
    "    X = Dense(n_vocab, activation='softmax')(X)\n",
    "    \n",
    "    model = Model(X_input, X)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "    return model\n",
    "#----------------------------------------------\n",
    "model = get_model(NetworkInput.shape[1:], n_vocab)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_4 to have shape (100, 32) but got array with shape (720, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-55543d405bf7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#-----------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNetworkInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNetworkOutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-91-55543d405bf7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, NetworkInput, NetworkOutput)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNetworkInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNetworkOutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#-----------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1630\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1631\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1478\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1481\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1482\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    121\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_4 to have shape (100, 32) but got array with shape (720, 1)"
     ]
    }
   ],
   "source": [
    "def train(model, NetworkInput, NetworkOutput):\n",
    "    filepath = './checkpoints/0/ckpt-{epoch:02d}-{loss:.4f}.hdf5'\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, save_best_only=True, mode='min')\n",
    "    callbacks=[checkpoint]\n",
    "    \n",
    "    model.fit(NetworkInput, NetworkOutput, epochs=200, batch_size=16, callbacks=callbacks)\n",
    "    return model\n",
    "#-----------------------------------\n",
    "trained_model = train(model, NetworkInput, NetworkOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620, 720, 1)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NetworkOutput.reshape(-1,NetworkOutput.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620, 100, 1)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NetworkInput.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
