{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from loss import sequence_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building model graph\n",
    "batch_size = 24\n",
    "droprate = .2\n",
    "epsilon = 1e-3\n",
    "n_prev_notes = 100\n",
    "n_features = 3 * 19\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_defahhhult():\n",
    "    \n",
    "    tf_input = tf.placeholder(tf.float32, shape = [batch_size, n_prev_notes * n_features], name='X')\n",
    "    tf_output = tf.placeholder(tf.float32, shape = [batch_size, n_features], name = 'Y')\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_producer(raw_data, batch_size, num_steps):\n",
    "    raw_data = tf.convert_to_tensor(raw_data, dtype=tf.int32, name='raw_data')\n",
    "    data_len = len(raw_data)\n",
    "    batches = data_len // batch_size - 1\n",
    "    \n",
    "    data = tf.reshape(raw_data[0:batch_size*batches], [batches, batch_size, 100, 57])\n",
    "    epoch_pieces = batches // num_steps\n",
    "    \n",
    "    i = tf.train.range_input_producer(epoch_pieces, num_epochs=1, shuffle=False, seed=0).dequeue()\n",
    "    x = data[ i * num_steps : (i+1) * num_steps, :, :, : ]\n",
    "    x.set_shape((num_steps, batch_size, 5700))\n",
    "    y = data[ i * num_steps + 1 : (i+1) * num_steps + 1, :, 0, : ]\n",
    "    y.set_shape((num_steps, batch_size, 57))\n",
    "    \n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Input(object):\n",
    "    def __init__(self, batch_size, num_steps, data):\n",
    "        self.batch_size = batch_size\n",
    "        self.num_steps = num_steps\n",
    "        self.epoch_pieces = (len(data) // batch_size - 1) // num_steps\n",
    "        self.input_data, self.targets = batch_producer(data, batch_size, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self, input_obj, is_training, hidden_size, num_layers, droprate=.3, init_scale=0.05):\n",
    "        self.input_obj = input_obj\n",
    "        #self.is_training = is_training\n",
    "        self.hidden_size = hidden_size\n",
    "        #self.num_layers = num_layers\n",
    "        #self.droprate = droprate\n",
    "        self.init_scale = init_scale\n",
    "        self.num_steps = self.input_obj.num_steps\n",
    "        self.batch_size = self.input_obj.batch_size\n",
    "        \n",
    "        inputs = self.input_obj.input_data\n",
    "        if is_training and droprate > 0 :\n",
    "            inputs = tf.nn.dropout(inputs, keep_prob=1-droprate, name='input_dropout')\n",
    "        \n",
    "        # set state storage\n",
    "        self.init_state = tf.placeholder(tf.float32, [num_layers, 2, self.batch_size, self.hidden_size],\n",
    "                                         'init_state')\n",
    "        # prepare it\n",
    "        state_per_layer_list = tf.unstack(self.init_state, axis=0)\n",
    "        rnn_tuple_state = tuple( tf.contrib.rnn.LSTMStateTuple(state_per_layer_list[idx][0],\n",
    "                                                              state_per_layer_list[idx][1])\n",
    "                               for idx in range(num_layers) )\n",
    "        \n",
    "        # create LSTM cell\n",
    "        cell = tf.contrib.rnn.LSTMCell(hidden_size)\n",
    "        # add more dropout to it\n",
    "        if is_training and droprate > 0 :\n",
    "            cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=1-droprate)\n",
    "        # adjust incase of more than 1 layer chosen\n",
    "        if num_layers > 1 :\n",
    "            cell = tf.contrib.rnn.MultiRNNCell([cell for _ in range(num_layers)])\n",
    "        \n",
    "        output, self.state = tf.nn.dynamic_rnn(cell, inputs, initial_state=rnn_tuple_state)\n",
    "        # output is in shape [ batch_size, num_steps, hidden_size ]\n",
    "        #----------------------------------------------------------------------------------\n",
    "        # Now define the softmax, loss and optimizer.\n",
    "        output = tf.reshape(output, (-1, hidden_size))\n",
    "        softmax_weights = tf.Variable(tf.random_uniform([hidden_size, note_elements],\n",
    "                                                        -init_scale,init_scale))\n",
    "        softmax_biases = tf.Variable(tf.random_uniform([note_elements], -init_scale, init_scale))\n",
    "        logits = tf.nn.xw_plus_b(output, softmax_weights, softmax_biases)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.python.ops as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.asarray([1,2, 3, 4, 5, 6, 7, 1,2 ,3, 4, 5]).reshape(2,6)\n",
    "tf.reduce_mean(b, axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
