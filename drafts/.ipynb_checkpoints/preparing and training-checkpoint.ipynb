{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import _pickle as pickle\n",
    "#import glob\n",
    "#from collections import OrderedDict\n",
    "#from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "#from music21 import note, chord, instrument, converter\n",
    "#import matplotlib.pyplot as plt\n",
    "#%matplotlib inline \n",
    "from lib.preprocessing import preprocess_raw_data, load_piece\n",
    "#from lib.lstm_model import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, all_data = preprocess_raw_data('./music/Mozart/', 'data/Mozart/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piece = load_piece('./data/Mozart/', 2)\n",
    "piece.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(piece, 1, 1, batch_size=20, model_save_name='./checkpoints/0/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-9b63d8a4b090>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#    logits = pickle.load(f)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./targets.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "import _pickle as pickle\n",
    "#with open('./logits.pkl', 'rb') as f:\n",
    "#    logits = pickle.load(f)\n",
    "with open('./targets.pkl', 'rb')  as f:\n",
    "    targets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2711, 100, 57)\n",
      "(2711, 100, 57)\n",
      "inputs (20, 30, 5700) init state Tensor(\"init_state:0\", shape=(1, 2, 20, 5700), dtype=float32)\n",
      "WARNING:tensorflow:From /home/bekora/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "(20, 30, 5700) LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_3:0' shape=(20, 5700) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_4:0' shape=(20, 5700) dtype=float32>)\n",
      "logits (600, 57)\n",
      "loss.py (600, 57) (20, 30, 57) (20, 30)\n",
      "cross Tensor(\"Loss/strided_slice_3:0\", shape=(?,), dtype=float32)\n",
      "(?, ?)\n",
      "Tensor(\"Loss/logistic_loss_1:0\", shape=(?, ?), dtype=float32)\n",
      "(?, ?)\n",
      "Tensor(\"Loss/logistic_loss_2:0\", shape=(?, ?), dtype=float32)\n",
      "[None] [None, None]\n",
      "cost Tensor(\"Loss/truediv_1:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.python.training.training' has no attribute 'Coordiantor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f1551800672a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpiece\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrearrange_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpiece\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpiece\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpiece\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_save_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'../checkpoints/0/model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/programming/my_projects/music_generator/lib/lstm_model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_data, num_layers, num_epochs, batch_size, model_save_name)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minit_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m                 \u001b[0mcoord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCoordiantor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0mthreads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_queue_runners\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.python.training.training' has no attribute 'Coordiantor'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from lib.preprocessing import load_piece, rearrange_data\n",
    "from lib.lstm_model import train\n",
    "piece = load_piece('../data/Mozart/', 0)\n",
    "piece = rearrange_data(piece)\n",
    "print(piece.shape)\n",
    "train(piece, 1, 1, batch_size=4, model_save_name='../checkpoints/0/model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piece.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rearrange_data(data, num_comb=100):\n",
    "    new_len = data.shape[0] - num_comb\n",
    "    new_data = np.zeros([ new_len, 100, 3, 19])\n",
    "    for i in range(new_len):\n",
    "        new_data[i] = data[i:i+num_comb]\n",
    "    new_data = new_data.reshape(-1, 100, 3*19)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npiece = rearrange_data(all_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npiece.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(notes, n_vocab):\n",
    "    ''' create input sequences and output notes '''\n",
    "    sequence_length = 100\n",
    "    NetworkInput = []\n",
    "    NetworkOutput = []\n",
    "    # create a mapping to the notes\n",
    "    mapper = LabelEncoder()\n",
    "    mapped_notes = mapper.fit_transform(notes)\n",
    "\n",
    "    for i in range(len(notes)-sequence_length):\n",
    "        in_seq = mapped_notes[i : i+sequence_length]\n",
    "        out_note = mapped_notes[i+sequence_length]\n",
    "        NetworkInput.append(in_seq)\n",
    "        NetworkOutput.append(out_note)\n",
    "    \n",
    "    n_patterns = len(NetworkOutput)\n",
    "    \n",
    "    NetworkInput = np.reshape(NetworkInput, (n_patterns, sequence_length, 1))\n",
    "    NetworkInput = NetworkInput / float(n_vocab)\n",
    "    \n",
    "    NetworkOutput = np.reshape(NetworkOutput, (-1,1))\n",
    "    hotencoder = OneHotEncoder(sparse=False)\n",
    "    _ = hotencoder.fit(mapped_notes.reshape(-1,1))\n",
    "    NetworkOutput = hotencoder.transform(NetworkOutput)\n",
    "    \n",
    "    # save the mapper and hotencoder to disk for prediction.\n",
    "    #with open('./data/mapper.pkl','wb') as f:\n",
    "    #    pickle.dump(mapper, f)\n",
    "    #with open('./data/hotencoder.pkl','wb') as f:\n",
    "    #    pickle.dump(hotencoder, f)\n",
    "    \n",
    "    print('Input shape = ',NetworkInput.shape, '\\nOutput shape = ', NetworkOutput.shape)\n",
    "    return mapped_notes, NetworkInput, NetworkOutput\n",
    "#---------------------------------------\n",
    "if debug : mapped_notes, NetworkInput, NetworkOutput = prepare_data(notes, n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('./checkpoints/1/loss_stack.pkl','wb') as f:\n",
    "#    pickle.dump(loss_stack, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(range(len(loss_stack)),loss_stack)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_files = glob.glob('./data/Mozart/*.pkl')\n",
    "#assert len(music_files) > 0\n",
    "#assert pieceId < len(music_files)\n",
    "with open(music_files[5], 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piano = parts.parts[0].recurse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = set()\n",
    "for p in piano :\n",
    "    if isinstance(p, note.Note):\n",
    "        names.add(p.name)\n",
    "    if isinstance(p, chord.Chord):\n",
    "        for pp in p.pitches:\n",
    "            names.add(pp.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenoct = set()\n",
    "octaves = set()\n",
    "for index,file in enumerate([glob.glob('./music/Mozart/*.mid')[2]]):\n",
    "        \n",
    "    if index % 10 == 0 : print(index,end='')\n",
    "    print('.',end='')\n",
    "    midi = converter.parse(file)\n",
    "    notes_to_parse  = []\n",
    "    parts = instrument.partitionByInstrument(midi)\n",
    "\n",
    "    if parts :\n",
    "        piano_notes = parts.parts[0].recurse()\n",
    "    else :\n",
    "        print('\\n*caution no parts are found.')\n",
    "        piano_notes = parts.flat_notes\n",
    "\n",
    "    # prepare notes\n",
    "    notes_to_parse = []\n",
    "    for elidx, element in enumerate(piano_notes):\n",
    "            elinf = [ element_info.copy() for i in range(3)]\n",
    "            if isinstance(element, note.Note):\n",
    "                elinf[0][str(element.name)] = 1\n",
    "                elinf[0][str(element.octave)] = 1\n",
    "                elinf[1]['empty'] = 1\n",
    "                elinf[2]['empty'] = 1\n",
    "                notes_to_parse.append(elinf)\n",
    "                octaves.add(element.octave)\n",
    "                data[elidx,0] = elinfo[0].values()\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                lenoct.add(len(element.pitches))\n",
    "                assert len(element.pitches) <= 3\n",
    "                for idx,e in enumerate(element.pitches) :\n",
    "                    elinf[idx][str(e.name)] = 1\n",
    "                    elinf[idx][str(e.octave)] = 1\n",
    "                    octaves.add(e.octave)\n",
    "                if idx != 2 :\n",
    "                    for i in range(idx, 3):\n",
    "                        elinf[i]['empty'] = 1\n",
    "                notes_to_parse.append(elinf)\n",
    "            else : # it shouldn't reach here.\n",
    "                pass\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenoct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_to_parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_names = ['A', 'B', 'B-', 'C', 'C#', 'D', 'E', 'E-', 'F', 'F#', 'G', 'G#']\n",
    "octaves = ['1', '2', '3', '4', '5', '6']\n",
    "element_info = OrderedDict({e:0 for e in ['empty'] + note_names + octaves})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.zeros([len(piano_notes), 3, 19], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0,0] = list(elinf[0].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
